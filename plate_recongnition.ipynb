import numpy as np
import cv2
import matplotlib.pyplot as plt
import os

paths='M:\\photos'
#os.chdir(path)
puts = []
vv= 1
u= 1881


for rep1,rep2,files in os.walk('M:\\photos') :
    for fichier in files :
        if fichier.endswith('.png') or fichier.endswith('.jpg') or fichier.endswith('.JPG') :
            chemin = paths+'\\'+fichier
            #puts.append(chemin)
            #a=cv2.imread(image_path)

            
            def plate_detector(path) :
                defaut_confiance = 0.5
                theshold = 0.5
                plat = []
                net = cv2.dnn.readNetFromDarknet('My_yolov3.cfg', 'My_yolov3_final.weights')

                layer_names = net.getLayerNames()
                layer_names = [layer_names[i-1] for i in net.getUnconnectedOutLayers()]

                with open('classes.names', 'r') as f :
                    labels = f.read().splitlines()

                image = cv2.imread(path)
                height, width, deep = image.shape

                blob = cv2.dnn.blobFromImage(image, 1/255, (416, 416), (0, 0, 0), swapRB = True, crop = False)
                net.setInput(blob)
                layerOutPuts = net.forward(layer_names)

                boxes = []
                confidences = []
                classIDs = []

                for output in layerOutPuts :
                    for detection in output :
                        scores = detection[5:]
                        classID = np.argmax(scores)
                        confidence = scores[classID]
                        if confidence > defaut_confiance :
                            box = detection[0:4]*np.array([width, height, width, height])
                            (centerX, centerY, W, H) = box.astype('int')
                            x = int(centerX - (W/2))
                            y = int(centerY - (H/2))
                            boxes.append([x, y, int(W), int(H)])
                            confidences.append(float(confidence))
                            classIDs.append(classID)

                    indexes = cv2.dnn.NMSBoxes(boxes, confidences, defaut_confiance, theshold)
                    colors = np.random.uniform(0, 255, size = (len(boxes), 3))
                #print(len(indexes), len(classIDs))
                if len(indexes) > 0 :
                    for i in indexes.flatten() :
                        (x, y, w, h) = boxes[i]
                        color = colors[i]
                        #text = '{}: {:.4f}'.format(labels[classIDs[i]], confidences[i])
                        image_plat = cv2.rectangle(image,(x,y),(x+w+60,y+h+30),color,3)
                        #cv2.putText(image,text, (x, y+20), cv2.FONT_HERSHEY_PLAIN, 2, color, 5)
                        image_ = image_plat[y:y+h+30, x:x+w+60]
                        try:
                            plat.append(cv2.resize(image_, (800, 400)))
                            #print(text)
                        except: continue
                    

                #cv2.imshow('image_plate', image)
                #cv2.waitKey(0)
                #print('i excecuted')
                return plat



            def rotation_plate(from_plate_detector):
                #plt.figure(figsize = (12*3, 8*3))
                i = 0
                total_air_chars_sorted = []
                dilation_ = []
                tree_rect =[]
                images= []
                for img_lp in from_plate_detector:
                    img_lp = cv2.resize(img_lp, (800, 400))
                    rows, cols, a = img_lp.shape

                    gray = cv2.cvtColor(img_lp, cv2.COLOR_RGB2GRAY)
                    # resize image to three times as large as original for better readability
                    gray = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)
                    gray1 = cv2.resize(gray, None, fx = 3, fy = 3, interpolation = cv2.INTER_CUBIC)

                    # perform gaussian blur to smoothen image
                    blur = cv2.GaussianBlur(gray, (5,5), 0)

                    # threshold the image using Otsus method to preprocess for tesseract
                    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)
                    # create rectangular kernel for dilation
                    rect_kern = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))
                    # apply dilation to make regions more clear
                    dilation = cv2.dilate(thresh, rect_kern, iterations = 1)
                    # find contours of regions of interest within license plate
                    try:
                        contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
                    except:
                        ret_img, contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    # sort contours left-to-right
                    sorted_contours = sorted(contours, key=lambda ctr: cv2.boundingRect(ctr)[0])

                    # create copy of gray image
                    im2 = gray.copy()
                    # create blank string to hold license plate number
                    plate_num = ""
                    # loop through contours and find individual letters and numbers in license plate
                    air_chars_sorted = []
                    for cnt in sorted_contours:
                        air_chars_sorte = x,y,w,h = cv2.boundingRect(cnt)
                        height, width = im2.shape
                        # if height of box is not tall enough relative to total height then skip
                        #if height / float(h) > 6: continue

                        ratio = h / float(w)
                        # if height to width ratio is less than 1.5 skip
                        if ratio < 0.6: continue
                        hauteur_img, largeur_img, profondeur = (img_lp.shape)
                        #if y > int(hauteur_img*1.2) : continue
                        
                        # if width is not wide enough relative to total width then skip
                        #if width / float(w) > 15: continue

                        area = h * w
                        # if area is less than 100 pixels skip
                        if area < 14000: continue

                        if area > 220000 : continue
                        # draw the rectangle
                        tree_rect.append(air_chars_sorte)
                        # grab character region of image
                        roi = thresh[y-5:y+h+5, x-5:x+w+5]

                        # perfrom bitwise not to flip image to black text on white background
                        try:
                            roi = cv2.bitwise_not(roi)
                            # perform another blur on character region
                            roi = cv2.medianBlur(roi, 5)
                            roi= cv2.resize(roi, (40, 60))
                            images.append(roi)
                        except: continue

                        air_chars_sorted.append(air_chars_sorte)
                    #print(len(tree_rect))
                    tree_index = []
                    for i in range(len(tree_rect)):
                        x,y,w,h = tree_rect[i]
                        for j in range(len(tree_rect)):
                            x_af,y_af,w_af, h_af = tree_rect[j] 
                            if (x<x_af)and((x+w)>(x_af+w_af))and(y<y_af):
                                tree_index.append(j)
                    #print(len(tree_index))
                    
                    for i,j in zip(tree_index, range(len(tree_index))):
                        i = i-j
                        tree_rect.pop(i)
                    #print(len(tree_rect))
                    for i in range(len(tree_rect)):
                        x,y,w,h = tree_rect[i]
                        rect = cv2.rectangle(im2, (x,y), (x+w, y+h), (0,255,0),5)
                    if len(air_chars_sorted) != 0 :
                        total_air_chars_sorted.append(air_chars_sorted)

                    rect = cv2.rectangle(im2, (x,y), (x+w, y+h), (0,255,0),5)

                    
                    air_chars_sorted = 0
                    plt.imshow(rect)
                    #cv2.imshow("Otsu Threshold", thresh)
                    i += 1
                return images   

                    

            img_founded = plate_detector(chemin)
            if (len(img_founded) != 0) :
                image_rotat = rotation_plate(img_founded)            
            
                for i in range(len(image_rotat)):
                    #plt.subplot(1, len(image_rotat), i+1)
                    #plt.imshow(image_rotat[i], cmap='gray')

                    #cv2.imwrite("C:\\Users\\badji\\Desktop\\project\\good project\\essaieyoloV3\\Modules_YOLOv3\\peit_data\\image_{}.png".format(u), image_rotat[i])
                    u= u+1 
    

            #print(vv)    
            vv= vv+1                             


    
